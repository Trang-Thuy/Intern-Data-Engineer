# Báo cáo tuần 7

> ### Bổ sung kiến thức, phần tìm hiểu về BigData, Hadoop, Spark
#### 1. Giải thích các định nghĩa _Block repeat heartbeat, write editLog_ trong ảnh

![Resolving the Failure Issue of NameNode - Knoldus Blogs](https://blog.knoldus.com/wp-content/uploads/2017/06/namenode.png)

**a. Block Report Heartbeat**
Định kỳ, các DataNode gửi heartbeat đến NameNode để thông báo nó vẫn hoạt động. 
- Heartbeat chỉ ra rằng DataNode vẫn đang hoạt động.
- BlockReport chứa thông tin như ID của block, độ dài block, vị trí block của block được lưu trữ trên DataNode. Thông tin này được NameNode sử dụng để theo dõi các block lưu trữ trong cụm

**b. Write/Read editLog**
Metadata trong NameNode được lưu trữ dưới dạng 2 file:
- FSImage: lưu trữ metadata của NameNode từ khi khởi tạo
- EditLogs: chứa thông tin thay đổi gần nhất của cụm chưa có trong FSImage

Hai file này rất quan trọng trong kiến trúc của HDFS. NameNode được cấu hình để lưu nhiều bản ghi của hai file này cùng một lúc, các cập nhật đều được đồng bộ đến các bản sao này. 

> Nguồn: [Learning Journal: Hadoop Architecture Part -2](https://www.learningjournal.guru/courses/hadoop/hadoop-foundation-training/hadoop-architecture-part-2/) và [SaturnCloud: How to Get Block Report from One Specific Rack in Hadoop](https://saturncloud.io/blog/how-to-get-block-report-from-one-specific-rack-in-hadoop/#:~:text=A%20block%20report%20is%20a,the%20location%20of%20the%20block.)

#### 2. Giải thích ảnh hưởng của Block size đến tốc độ MapReduce
Theo lý thuyết, Các DataNode trong HDFS lưu trữ dữ liệu dưới dạng các block, mỗi block có giá trị mặc định là 128MB. 
Tuy nhiên theo em tìm hiểu, nếu tăng kích thước của block trên HDFS có thể làm tăng tốc độ MapReduce. 
- Nếu tăng kích thước của block, số lượng block của file ít hơn, dẫn đến kích thước của metadata trong NameNode giảm, tương đương với việc lượng công việc của NameNode giảm xuống. Đối với các hệ thống file dữ liệu lớn, đây là một sự cải thiện đáng kể
- Ngoài ra, với số lượng block ít hơn, quá trình lập lịch cho tác vụ đơn giản hơn, nên lượng công việc của Scheduler (trong MapReduce) cũng giảm
> Khi tăng kích thước block, với các file có kích thước là 512MB, 1GB, 1.5GB và 2GB, thời gian thực hiện MapReduce cải thiện (giảm) 2.9%

Tuy nhiên, nếu cân nhắc đến hiệu suất của hệ thống Hadoop thì kích thước block có những ảnh hưởng sau:
- Kích thước block càng nhỏ, thời gian tìm kiếm block dữ liệu càng lâu
- Kích thước block quá lớn, mức độ song song của dữ liệu sẽ giảm, hiệu quả xử lý dữ liệu phân tán giảm

Vì vậy, kích thước của block trong HDFS cần được tối ưu. Hiện nay kích thước mặc định của block là 128MB


> Nguồn: [The Effect Analysis of Block Size in HDFS Againts MapReduce Speed Process](https://www.academia.edu/14636656/The_Effect_Analysis_of_Block_Size_in_HDFS_Againts_MapReduce_Speed_Process) và [Effects of Design Factors of HDFS on I/O Performance](https://thescipub.com/pdf/jcssp.2018.304.309.pdf)

#### 3. Rack là gì

HDFS là một hệ thống file phân tán, ta cần kết nối nhiều máy tính lại và tạo thành một cụm
Rack là khái niệm tập hợp các máy tính (khoảng 30 đến 40 máy) trong cùng hệ thống mạng, sử dụng chung network switch.

Các đặc điểm của rack:
- Các máy tính này thường có tốc độ kết nối với nhau nhanh hơn so với kết nối đến các máy bên ngoài Rack: Rack được cấp một nguồn điện và bộ chuyển mạch chuyên dụng. Nếu công tắc bị lỗi hoặc nguồn điện cung cấp cho một rack có vấn đề, tất cả máy tính thuộc rack đó có thể bị mất kết nối. Hệ thống HDFS có nhiều rack, mỗi rack có công tắc riêng, các công tắc này được kết nối với một công tắc chính. 
- Về phân bố của các block trên DataNode thuộc Rack: Sau khi sao chép các bản ghi của block, HDFS thực hiện ghi block đầu tiên vào DataNode đầu tiên trên một máy, 2 bản sao còn lại sẽ ghi vào 2 DataNode thuộc Rack khác với Rack ban đầu. 
- Thuật toán Rack Awareness giúp nâng cao khả năng chịu lỗi của HDFS. Giả sử, trong trường hợp có một DataNode lỗi thì vẫn còn 2 DataNode khác sẵn sàng. Hoặc trường hợp tất cả các DataNode của cùng một Rack chết thì vẫn còn DataNode ở Rack khác sẵn sàng. Ngoài ra, điều này cũng có lợi cho việc đọc/ghi file.

> Nguồn: [Hadoop Apach: HDFS Architecture](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html?fbclid=IwAR0d2KYg5jV_hJUv5i8ghVAJe-UVX2E4Qbhy-5wVIfNeOUYERW-W3aXvhVE)

#### 4. Nếu cần phải gom đủ tối đa 128MB dữ liệu, dữ  liệu mới được ghi xuống block, tính khả năng chịu lỗi có được đảm bảo không?
Sai
#### 5. DataNode sẽ thông báo đến người dùng rằng đã ghi dữ thành công trước hay sau khi hoàn tất quá trình tạo các bản sao?
![HDFS Tutorial: Read & Write  Commands using Java API](https://www.guru99.com/images/Big_Data/061114_0923_LearnHDFSAB2.png))
> Nguồn: [Guru99 - HDFS Tutorial: Architecture, Read & Write Operation using Java API](https://www.guru99.com/learn-hdfs-a-beginners-guide.html?fbclid=IwAR0J8VWZs9xu_4DnsSKt3X2o04zaYl0rOCGT7YMi8i7ljEjhHb7Pbqj62tY#2)
#### 6. Trong hàm _Shuffle_, sau khi map, dữ liệu sẽ được shuffling để tập hợp các key giống nhau về cùng một partition
#### 7. MapReduce: kết quả sau khi map, shuffle và sort được lưu ở đâu, như thế nào trước khi Reducer đọc
#### 8. Tìm hiểu hai cơ chế khởi động lại Resource Manager: bảo vệ và không bảo vệ
#### 9. Resource Manager đồng bộ StandbyResource Manager như thế nào
#### 10. YARN cluster: Liệt kê & phân tích ưu điểm, nhược điểm của Cluster mode - Client node 
#### 11. Nêu các phép chỉ có thể thực hiện trên Dataset, không thực hiện trong DataFrame
#### 12. Tìm hiểu về định dạng (format) của narrow, wide (shuffles) trao đổi giữa các cặp key-value
#### 14. Có bao nhiêu replicate ở ddaau
#### 15. Trình tự đọc ghi và thứ tự ưu tiên đọc/ghi (data localogta)
#### 16. Tìm hiểu workflow của NameNode High Availability và YARN


> Written with [StackEdit](https://stackedit.io/).
