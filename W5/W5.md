# Báo cáo tuần 5 - 6 - 7
## Yêu cầu:
### 1. Tìm hiểu về bigdata. tham khảo khóa bigdata trên educative 
> link khóa học: https://www.educative.io/courses/introduction-to-big-data-and-hadoop/gkNGDgZPY93) 
> Tham khảo doc: https://docs.google.com/document/d/1DNDmlSyefGOA83d0ugFABpK5BmC_FK9G9pp_SIOWm2s/edit
#### 2.1. Dữ liệu lớn và Hadoop ecosystem, khai niệm cơ bản về hdfs, yarn, spark
>#### 2.2. Hadoop ecosystem
>#### 2.3. HDFS:
>#### 2.4. Yarn
#### 2.5. Spark
>2.2. Quá trình đọc ghi trong hdfs, khái niệm namenode, datanode, secondary namenode, hdfs block, block 
replication
2.3.  Các thành phần của yarn, khái niệm về mapreduce

2.4.  Các thành phần của spark, spark api (action, tranformation)
### 3. Các khái niệm nâng cao
3.1. HA trong hdfs (khái niệm JournalNode, zookeeper)
3.2.  Khái niệm editlog, stand by namenode, fs image
## Nội dung
## 1. BigData

#### 2.1. Dữ liệu lớn 
Big Data là một thuật ngữ dành cho các tập dữ liệu không thể xử lý hiệu quả nếu chỉ sử dụng phương pháp truyền thống như RDBMS.

![](https://lh3.googleusercontent.com/Qho08JHhFm6fvG2P-h0WDtPU3qKbfEwKMlbvkWfcyK7h4UjQ1qO_KhhlH42B1ilunbUr7jUBc5D90VQUXCGwFSYnMV-sNbkWRLboKjgwmq_NZuBe0PeIqPuI0vQ1IbKZzas2m2kXGiaZNlPbK6vpYQ)

Ba thách thức chính trong dữ liệu lớn: Variety, Velocity, Volume. 
So sánh BigData với Data Warehouse:
- Data Warehouse: có cấu trúc, lược đồ, cơ sở dữ liệu quan hệ
- BigData: cấu trúc lỏng lẻo, thường là dữ liệu chưa chọn lọc
#### 2.2. Hadoop Ecosystem
Apache Hadoop: là một framework mã nguồn mở, hỗ trợ hệ thống tương tác với Big Data một cách dễ dàng hơn, cho phép xử lý các tập dữ liệu lớn dạng cụm. Hadoop được tạo từ một số modules. Hadoop Ecosystem gồm có 4 thành phần chính: HDFS, MapReduce, Yarn và Hadoop Common

![Hình anhr1](https://media.geeksforgeeks.org/wp-content/cdn-uploads/HadoopEcosystem-min.png)
 **HDFS (Hadoop Distributed File System)**: là thành phần chính, chịu trách nghiệm lưu trữ các tệp dữ liệu lớn gồm dữ liệu có cấu trúc hoặc không có cấu trúc trên cácacs nút khác nhau, duy trì siêu dữ liệu (metadata là dữ liệu về dữ liệu) dưới dạng file log.

HDFS có hai thành phần cốt lõi: 
- Nút tên: nút chính chứa siêu dữ liệu (metadata) yêu cầu ít tài nguyên hơn so với các nút dữ liệu lưu trữ thực tế. 
- Các nút dữ liệu: là phần cứng thông thường (commodity hardware) trong môi trường phân tán, giúp Hadoop tiết kiệm chi phí.

Vì HDFS hoạt động ở trung tâm của hệ thống, nên nó duy trì tất cả sự phối hợp giữa các cụm dữ liệu và phần cứng.

**YARN (Yet Another Resource Negotiator):** là thành phần giúp quản lý tài nguyên trên các cụm dữ liệu. Tóm lại, thành phần thực hiện công việc lập lịch và phân phát tài nguyên cho hệ thống. YARN gồm 3 thành phần chính:
- Quản lý tài nguyên (Resource Manager): có đặc quyền phân bố tài nguyên cho các ứng dụng trong hệ thống
- Quản lý nút (Nodes Manager): làm việc trên việc phân bổ tài nguyên như CPU, bộ nhớ, băng thông trên mỗi máy 
- Quản lý ứng dụng (Application Manager): hoạt động như một giao diện giữa quản lý tài nguyên và quản lý nút, thực hiện việc đàm phán, tương tác theo yêu cầu hai bên

**MapReduce (Programming based Data Processing):** Bằng cách ứng dụng thuật toán phân tán và song song, MapReduce cho phép thực hiện quá trình xử lý và giúp viết các ứng dụng chuyển đổi tập dữ liệu lớn thành một tập dữ liệu có thể quản lý được.
- hàm `Map()`: thực hiện sắp xếp và lọc dữ liệu, tổ chức quản lý dữ liệu dưới dạng nhóm. Map tạo ra cặp key-value dựa trên kết quả
- hàm `Reduce()`: thực hiện tổng hợp dữ liệu được ánh xạ. `Reduce()` lấy đầu ra của hàm `Map()` làm đầu vào và kết hợp các bộ dữ liệu đó thành các bộ dữ liệu có kích thước nhỏ hơn.

**PIG, HIVE (Query based processing of data service)**: là ngôn ngữ dựa trên truy vấn tương tự như SQL. 
- PIG là một nền tảng, có mục đích sử dụng để cấu trúc luồng dữ liệu, xử lý và phân tích các tập dữ liệu lớn. PIG thực hiện công việc thực thi các lệnh ở chế độ nền. Sau khi xử lý, PIG lưu trữ kết quả HDFS
- HIVE: thực hiện đọc và ghi các tập dữ liệu lớn. Nó có khả năng mở rộng cao vì nó cho phép xử lý thời gian thực và xử lý dữ liệu hàng loạt. Ngoài ra, tất cả dữ liệu SQL đều được HIVE hỗ trợ, giúp quá trình xử lý truy vấn dễ dàng hơn. 

**Mahout**: cho phép các hệ thống, ứng dụng có khả năng học máy, giúp hệ thống được đào tạo dựa trên một số mẫu, tương tác giữa người dùng với môi trường hay cơ sở các thuật toán.
Các thư viện như lọc cộng tác, phân cụm, phân loại dữ liệu cũng được cung cấp ở thành phần này

**Apache Spark**: là một nền tảng xử lý các tiến trình tiêu thụ như xử lý hàng loạt, xử lý tương tác thời gian thực hay xử lý lặp lại thời gian thực, chuyển đổi biểu đồ, trực quan hóa...
Spark phù hợp với dữ liệu thời gian thực, Hadoop phù hợp với dữ liệu có cấu trúc và xử lý hàng loạt.

**Apache HBase**: Đây là một cơ sở dữ liệu NoSQL, hỗ trợ nhiều loại dữ liệu vì vậy nó có khả năng xử lý mọi vấn đề của CSDL Hadoop. HBase cung cấp khả năng của BigTable từ Google, vì vậy nó có thể hoạt động hiệu quả trên các tập dữ liệu lớn. 
Khi người dùng cần tìm kiếm, truy xuất tần suất xuất hiện của một dữ liệu nhỏ trong tập dữ liệu lớn, yêu cầu này cần được xử lý trong một khoảng thời gian ngắn và nhanh chóng. Việc sử dụng Apache HBase sẽ giúp vấn đề trên được xử lý dễ dàng.

**Solr, Lucene**: thực hiện nhiệm vụ tìm kiếm và tập chỉ mục bằng cách sử dụng một số thư viện java. Ngoài ra, Lucene dựa trên Java còn có cơ chế kiểm tra chính tả.

**Zookeeper**: Zookeeper hỗ trợ xử lý vấn đề liên quan đến quản lý phối hợp và đồng bộ hóa giữa các tài nguyên hoặc các thành phần trong Hadoop. Zookeeper thực hiện đồng bộ hóa, liên lạc dựa trên liên thành phần, nhóm và bảo trì.

**Oozie**: thực hiện nhiệm vụ lập lịch, lên lịch các công việc và liên kết chúng thành một đơn vị duy nhất. Có hai loại nhiệm vụ chính: Oozie workflow và Oozie coordinator. 
- Oozie workflow: là các công việc cần thực thi một cách tuần tự
- Oozie coordinator: là các công việc được kích hoạt khi được cung cấp một số dữ liệu hoặc một số yếu tố bên ngoài khác.               
### 2.2. HDFS (Hadoop Distributed File System)
Vấn đề liên quan đến lưu trữ dữ liệu trong máy là một vấn đề quan trọng, cấp thiết khi tốc độ dữ liệu đang ngày càng tăng. Giải pháp đặt ra là, lưu trữ dữ liệu trên một mạng máy móc, hay còn gọi là lưu trữ trên hệ thống tập dữ liệu phân tán. HDFS được thiết kế để cung cấp dung lượng lưu trữ cho các tệp cực lớn (dung lượng lên tới 1000TB) với **_mẫu truy cập dữ liệu trực tuyến_** và có thể chạy trên các phần cứng thông thường. 
> _**Mẫu truy cập dữ liệu trực tuyến**_: HDFS được thiết kế với nguyên tắc ghi một lần và đọc nhiều lần. Sau khi dữ liệu được ghi, các phần lớn dữ liệu có thể được xử lý bất kì lúc nào.

![Hình ảnh](https://media.geeksforgeeks.org/wp-content/cdn-uploads/NameNode-min.png)

**a. Kiến trúc của HDFS**

*Node*: các nút trong cụm HDFS là các nút kiểu master-slave
- **NameNode (Master Node)**: nút này có nhiệm vụ quản lý các nút slave và phân công công việc cho các nút kia
	- Ngoài ra, nó thực thi các hoạt động liên quan đến hệ thống không gian tên như đóng, mở, đổi tên tệp và thư mục
	- NameNode nên được triển khai trên phần cứng tin cậy và có cấu hình cao.
- **DataNode (Slave Node)**: thực hiện nhiệm vụ như đọc, viết, xử lý.
	- Các nút này thực hiện các nhiệm vụ như tạo, xóa, sao chép theo yêu cầu từ nút master (NameNode)
	- DataNode có thể được triển khai trên phần cứng thông thường. 

**HDFS Daemon**: đây là các tiến trình chạy ở chế độ nền
- NameNodes: chạy ở nút master. Nút này lưu trữ metadata (các dữ liệu thông tin về dữ liệu như đường dẫn tệp, số lượng khối dữ liệu, ID khối dữ liệu...). Nó cần dung lượng RAM cao vì cần lưu trữ các metadata trong RAM để có thể truy xuất dữ liệu nhanh chóng, giảm thời gian tìm kiếm. Tuy nhiên, các bản sao dữ liệu liên tục của nút được sao lưu ở đĩa
- DataNodes: chạy ở nút slave. Các dữ liệu thực sự được lưu trữ tại nút này nên dung lượng bộ nhớ cần thiết khá lớn.

**b. Lưu trữ dữ liệu trong HDFS** 

Giả sử, có một tập dữ liệu có dung lượng 100TB được thêm vào hệ thống. Đầu tiên, nút master (hay NameNode) sẽ chia tập dữ liệu thành các khối dữ liệu có độ lớn là 10TB (kích thước mặc định là 128MB với các phiên bản Hadoop 2.x trở lên). Các khối dữ liệu sẽ được lưu trữ trong các nút slave (DataNode). Các nút DataNode sẽ sao chép các khối và gửi các thông tin về dữ liệu, khối dữ liệu đến nút master. Hệ số sao chép mặc định là 3, có nghĩa là mỗi khối dữ liệu sẽ tạo ra 3 bản sao. Hệ số sao chép này có thể thay đổi tùy nguời sử dụng. 

Một số vấn đề khác liên quan đến lưu trữ dữ liệu trong HDFS:
- Nút master: chứa metadata nên nút này biết các thông tin, vị trí của các nút slave (DataNode), cungx như khối dữ liệu của nút. Các hoạt động đều phải thông qua sự cho phép của nút này
- Nhờ cơ chế phân chia tệp dữ liệu lớn thành các khối có kích thước 128MB, thời gian truy cập & tìm kiếm dữ liệu được tiết kiệm. Việc thực hiện các thao tác đọc/ghi khác nhau trên các khối trở nên dễ dàng.
- Ngoài ra, cơ chế sao chép các khối dữ liệu trong các nút slave cũng đảm bảo khả năng chịu lỗi của HDFS. Giả sử nếu dữ liệu không được sao chép, nếu một nút dữ liệu gặp sự cố, khối này sẽ bị hủy. Điều này dẫn đến việc dữ liệu tổng thể không nhất quán và bị lỗi. Vậy nên, cơ chế sao chép các khối dữ liệu này là rất cần thiết.
- Nút slave sẽ liên tục gửi tín hiệu (heartbeat) đến nút master. Nếu nút master không nhận được tín hiệu từ một nút slave thì nút master sẽ ghi nhận rằng nút kia đã chết (lỗi)
- Cơ chế cân bằng: khi một nút slave bị hỏng, các khối dữ liệu được lưu trữ trên đó cũng sẽ biến mất, dẫn đến việc số lượng bản sao khối dữ liệu sẽ thấp hơn so với các khối dữ liệu thuộc nút khác. Tại đây, nút master sẽ gửi tín hiệu các các nút slave chứa các bản sao của các khối bị mất để sao chép cho việc phân phối các khối dữ liệu được cân bằng
- Cơ chế sao chép khối dữ liệu: Không tồn tại hai khối dữ liệu là hai bản sao của cùng một dữ liệu trên cùng một nút slave.

**c. Quá trình đọc ghi trong HDFS**

_Quá trình ghi file:_ HDFS dùng để lưu trữ dữ liệu lớn, vì vậy việc đọc ghi file là một tiến trình thường xuyên xảy ra trong công cụ này. Các yêu cầu đọc ghi từ máy khách (client) đều phải đi qua NameNode, tại đây NameNode sẽ tiến hành điều phối cg việc, giao các tác vụ cho DataName. Cơ chế đọc ghi trong HDFS là "Read Once - Write Many", người dùng có thể viết file một lần và đọc nhiều lần. Người dùng không thể chỉnh sửa file mà chỉ có thể append thêm nội dung vào file. 

Khi máy khách (client) submit một request ghi file, file đó sẽ được chia thành các block nhỏ (có kích thước mặc định là 128MB). Quy trình ghi file trong HDFS tuân theo giao thức sau:
- Client gửi yêu cầu ghi file đến NameNode, NameNode kiểm tra quyền và trả lại Client danh sách DataNote mà Client sẽ ghi các block này
- Việc lựa chọn DataNode là tùy thuộc vào tính khả dụng, số lượng replicate và RackAwareness là do NameNode quyết định
- Khi Client nhận được thông tin về danh sách DataNode, việc ghi sẽ tiến hành theo 3 bước:
	- Chuẩn bị pipeline: Trước khi tiến hành ghi dữ liệu, Client kiểm tra các DataNode trong tình trạng sẵn sàng nhận dữ liệu hay chưa. Để kiểm tra, với mỗi block, Client sẽ kết nối đến các DataNode và kiểm tra. 
	
	>Giả sử với block A được NameNode quyết định ghi vào DataNode 1, 5 và 6. Client tạo một kết nối TCP/IP đến DataNode 1. Client thông báo DataNode1 hãy sẵn sàng cho việc ghi dữ liệu, đồng thời gửi kèm danh sách 2 DataNode tiếp theo mà block A sẽ tạo tạo bản sao và lưu trữ là DataNode 5 và 6. DataNode 1 sau đó sẽ kết nối đến DataNode 5 để thông báo việc ghi dữ liệu. DataNode 5 thông báo đến Data Node 6 về việc ghi dữ liệu. 
	>
	> Sau khi các bước thông báo hoàn tất, lần lượt DataNode 6 phản hồi DataNode 5, DataNode 5 phản hồi DataNode 1, DataNode 1 phản hồi client về việc sẵn sàng ghi dữ liệu. 
		>
	> Nếu có gì bất thường dẫn đến việc tồn tại một DataNode không sẵn sàng, NameNode gửi lại thông tin danh sách DataNode mới cho Client.
	- Đẩy dữ liệu và tạo bản sao: Sau khi hoàn tất bước chuẩn bị pipeline, dữ liệu bắt đầu được ghi từ client đến DataNode đầu tiên, sau đó các DataNode sẽ tự tạo bản sao (replicate) cho nhau
	
	> Trong ví dụ trên, Client ghi dữ liệu vào DataNode 1. DataNode 1 kết nối đến DataNode 5 và ghi dữ liệu vào DataNode 5. DataNode 5 ghi dữ liệu xong kết nối và ghi dữ liệu đến DataNode 6.
	- Nhận thông tin phản hồi: Sau khi việc đẩy dữ liệu và sao chép hoàn tất, các DataNode sẽ tuần tự gửi acknowlegement về cho client. Khi DataNode đầu tiên được ghi gửi ack cho client, thông báo rằng block đã được ghi thành công, client thông báo cho NameNode, NamNode thông báo metadata về thông tin vị trí block mới được ghi thành công và ngắt kết nối TCP/IP

Việc ghi dữ liệu này được tiến hành song song trên các block. Giả sử file dữ liệu ban đầu có 3 block cần ghi thì cả ba block đều được ghi cùng lúc. 

**_Quá trình đọc trong HDFS:_** Cơ chế đọc trong HDFS khá đơn giản, gồm cá bước:
- Client bắt đầu yêu cầu đọc bằng phương thức `open()` trong object DistributedFileSystem
- Object kết nối đến NameNode để lấy thông tin metadata về vị trí của các block của file
- NameNode trả về cho máy khách (client) thông tin metadata của block
- Khi client nhận được metadata của DataNode, đồng thời nó cũng nhận được object FSDataInputStream. Object này chứa DFSInputStream chịu trách nhiệm giao tiếp với DataNode. Client gọi phương thức `read()`, DFSInputStream khởi tạo kết nối với DataNode
- Dữ liệu được client gọi liên tục từ đầu đến cuối của block qua phương thức `read()`
- Khi đọc xong một block, client tiếp tục đọc các block tiếp theo
- Khi đã đọc xong các block cần đọc, client() ngắt kết nối bằng phương thức `close()`
Khi NameNode gửi thông tin vị trí các DataNode chứa các block cho client, NameNode sẽ ưu tiên chọn các bản sao (replica) có vị trí gần với client nhất, nhằm mục đích giảm thiểu tốc bộ băng thông.

**d. Ưu điểm & hạn chế của HDFS**

Ưu điểm: 
- Lưu trữ dữ liệu phân tán
- Dữ liệu được phân chia thành các khối dữ liệu giúp tiết kiệm thời gian tìm kiếm
- Dữ liệu có tính khả dụng cao vì cùng một khối dữ liệu sẽ có nhiều bản sao 
- Độ tin cậy cao 
- Khả năng chịu lỗi cao

Hạn chế của HDFS:
- Truy cập dữ liệu có độ trễ thấp: HDFS được thiết kế để lưu trữ dữ liệu lớn, đánh đổi với yêu cầu quyền truy cập dữ liệu có độ trễ thấp
- Đối với các tệp dữ liệu nhỏ: cần tìm kiếm và chuyển đổi từ nút slave này sang nút slave khác để truy xuất từng tệp dữ liệu nhỏ. Trường hợp này là một quá trình truy cập dữ liệu kém hiệu quả.
### 2.3. YARN
**YARN (Yet Another Resource Negotiator)**: được thiết kế để loại bỏ vấn đề thắt nút cổ chai trên Job Tracker trong phiên bản Hadoop 1.0. Sau này, YARN đã được phát triển thành hệ điều hành phân tán quy mô lớn nhằm mục đích xử lý Bigdata.

YARN quản lý dữ liệu được lưu trữ trong HDFS. YARN sử dụng các công cụ xử lý dữ liệu như: xử lý đồ thị, tương tác, quản lý luồng cũng như quản lý hàng loạt. YARN tự động phân chia các tài nguyên khác nhau và lên lịch quản lý ứng dụng. 

Các đặc điểm của YARN:
- Khả năng mở rộng: Bộ lập lịch trong Trình quản lý tài nguyên của kiến trúc YARN cho phép Hadoop mở rộng và quản lý hàng nghìn nút và nụm
- Khả năng tương thích: YARN hỗ trợ các ứng dụng map-reduce mà không gây gián đoạn
- Sử dụng cụm: YARN hỗ trợ sử dụng phân cụm động trong Hadoop

![Hình ảnh](https://media.geeksforgeeks.org/wp-content/uploads/HadoopYarn.jpg)

**a. Kiến trúc YARN**

**Client**: Máy khách gửi các nhiệm vụ map-reduce

**Resource Manager**: là thành phần chính của YARN, chịu trách nhiệm phân chia và quản lý tài nguyên cho tất cả ứng dụng. Bất cứ khi nào thành phần này nhận được yêu cầu xử lý, nó sẽ chuyển tiếp yêu cầu đến _Node Manager_ tương ưng, và phân bổ tài nguyên để nút hoàn thành yêu cầu. _Resource Manager_ gồm 2 thành phần chính:
- **Scheduler**: thực hiện lập lịch dựa trên ứng dụng được phân bổ và các tài nguyên có sẵn. Thành phần này không thực hiện các tác vụ khác như giám át, theo dõi, khởi động lại nếu một tác vụ không thành công. _YARN Scheduler_ hỗ trợ các plugin như _Capacity Scheduler_ và _Fair Scheduler_ để phân vùng tài nguyên
- **Application Manager**: chịu trách nhiệm chấp nhận ứng dụng và xem xét vùng chứa đầu tiên từ trình quản lý tài nguyên. Nếu tác vụ không thành công, _Application Manager_ sẽ khởi động lại _Application Master_

**Node Manager**: đảm nhận quản lý các nút đơn trên cụm Hadoop, quản lý ứng dụng và quy trình làm việc của nút. Nhiệm vụ chính cuả thành phần này là: tương tác để theo kịp _Resource Manager_. Nó đăng kí với _Resouce Manager_, gửi _heat beat_ để cập nhật tình trạng của nút. _Node Manager_ cũng giám sát việc sử dụng tài nguyên, quản lý log, hủy vùng chứa dựa trên chỉ dẫn từ _Resource Manager_. Ngoài ra, thành phần nà cũng chịu trách nhiệm tạo vùng chứa và khởi động theo yêu cầu của _Application Master_.

**Application Master**: 

**Container**: tập hợp các tài nguyên vật lý như RAM, lõi CPU, ổ đĩa trên một nút duy nhất. 

**b. Luồng thực hiện ứng dụng trong YARN**
![ha](https://media.geeksforgeeks.org/wp-content/uploads/Application_WorkFlow_YARN.jpg)

Bước 1: Máy khách gửi đơn (application) đến _Resource Manager_

Bước 2: _Resource Manager_ phân chia một vùng chứa để khởi động _Application Manager_

Bước 3: _Application Manager_ tự đăng kí với _Resource Manager_

Bước 4: _Application Manager_ đàm phán các vùng chứa từ _Resource Manager_

Bước 5: _Application Manager_ gửi các thông báo đến _Node Manager_ để khởi chạy các vùng chứa

Bước 6: Đoạn code được thực thi trong các vùng chứa

Bước 7: _Resource Manager_ gửi các thông báo nhằm mục đích theo dõi trạng thái của các tác vụ đến máy khách

Bước 8: Khi quá trình xử lý hoàn tất, _Application Manager_ hủy đăng ký với _Resource Manager_

**c. Ưu điểm & Nhược điểm của YARN**

Ưu điểm của YARN:
- Độ linh hoạt: YARN cung cấp tính linh hoạt để chạy nhiều loại hệ thống xử lý phân tán khác nhau như Apache Spark, Apache Flink, Apache Storm... Ngoài ra, nó còn chó phép nhiều công cụ xử lý chạy đồng thời trên một cụm đơn Hadoop
- Quản lý tài nguyên hiệu quả: YARN cho phép quản trị viên phân bố và giám sát các tài nguyên (như CPU, bộ nhớ, dung lượng ổ đĩa...) theo yêu cầu đăng ký trong một cụm
- Khả năng mở rộng: được thiết kế nhằm mục đích mở rộng cao và có thể xử lý hàng nghìn nút trong một cụm, YARN có thể tăng, giảm quy mô này dựa trên yêu cầu của các ứng dụng đang chạy trên cụm
- Hiệu suất: cung cấp hiệu suất tốt bằng cách cung cấp một hệ thống quản lý tài nguyên tập trung. Nó đảm báo rằng các tài nguyên được sử dụng tối ưu và các ứng dụng được lên lịch hiệu quả trên tài nguyên có sẵn
- Bảo mật mạnh mẽ: nhờ các tính năng Kerberos, truy cập Secure Shell (SSH) và truyền dữ liệu an toàn, YARN đảm bảo dữ liệu được lưu trữ và xử lý trên cụm Hadoop là an toàn.

Hạn chế của YARN:
- Độ phức tạp: thành phần YARN làm tăng mức độ phức tạp hơn cho Hadoop ecosystem. Nó yêu cầu những thành phần cài đặt bổ sung, có thể gây khó khăn cho những người dùng không quen sử dụng YARN
- Chi phí: Để quản lý tài nguyên và lập lịch ứng dụng, chi phí bổ sung này có thể làm chậm hiệu suất của cụm Hadoop
- Độ trễ: Do phân bổ tài nguyên, lập trình ứng dụng và giao tiếp giữa các thành phần, độ trễ bổ sung có thể gây ra bởi YARN
- Một điểm bị lỗi: YARN có thể là một điểm đơn lỗi trong cụm Hadoop. Nếu YARN lỗi, nó có thể dẫn đến toàn bộ cụm phải dừng lại. Để tránh trường hợp này xảy ra, quản trị viên có thể cài đặt một phiên bản YARN backup để tăng tính khả dụng
- Hỗ trợ hạn chế: Với các ngôn ngữ lập trình khác Java, mặc dù YARN hỗ trợ nhiều công cụ xử lý nhưng vẫn còn một số hạn chế khả năng sử dụng trong một số môi trường nhất định.

### 2.4. Map Reduce
#### a. Map và Reduce
Đây là thành phần trong Hadoop chịu trách nhiệm xử lý các tệp tin. _Map Reduce_ có hai tác vụ chính được chia theo giai đoạn: tác vụ Map và tác vụ Reduce.

![Hình ảnh](https://media.geeksforgeeks.org/wp-content/uploads/20230523164846/mapreduce-workflow-768.png)

Sau khi dữ liệu được lưu trữ ở nút Data và các siêu dữ liệu được lưu trữ ở nút Name trong HDFS, nếu người dùng muốn xử lý, tthay vì chuyển dữ liệu đến máy local thì truy vấn sẽ được thực hiện trên dữ liệu. _Job Tracker_ sẽ được sử dụng để theo dõi câu truy vấn này. Đầu tiên _Job Tracker_ sẽ truy vấn nút Namde để chạy yêu cầu trên dữ liệu. Nút Name sẽ cung cấp siêu dữ liệu, gửi đến _Job Tracker_. Sau khi đọc siêu dữ liệu, _Job Tracker_ đã nắm được ví trị phân bố của các tệp trong HDFS, nó sẽ tương tác với _Task Tracker_ của các tệp dữ liệu. Tuy nhiên _Job Tracker_ chỉ tương tác với bản sao của tệp gần nó nhất.

Việc chạy đoạn code truy vấn trên các tệp được gọi là **Map**. Trong Haddop, số lượng trình ánh xạ cho tệp đầu vào bằng số lần phần tách đầu vào của tệp. Giả sử, tệp đầu vào _sample.txt_ có 4 phân tách đầu vào là _first.txt, second.txt, third.txt_ và _fourth.txt_, sẽ có 4 trình ánh xạ (mapper) chạy để xử lý tệp. _Job Tracker_ có nhiệm vụ xử lý những trình ánh xạ này. 
Lưu ý: Vì _Task Tracker_ là dịch vụ con của _Job Tracker_, nên nếu trường hợp tồn tại một máy cục bộ bị hỏng, toàn bộ quá trình xử lý của tệp sẽ dừng lại. 
- Mỗi _Task Tracker_ sẽ gửi heartbeat và số lượng vị trí của nó đến _Job Tracker_ theo chu trình 3s. Nếu sau 30s không nhận được bất kì heartbeat nào từ _Task Tracker_, _Job Tracker_ sẽ xác nhận rằng _Task Tracker_ này đã chết, hoặc rất bận. Sau đó, nó sẽ tương tác với _Task Tracker_ của một bản sao khác cùng tệp, yêu cầu trả lời các truy vấn mà nó mong muốn. 
Tương tự, thông tin về vị trí của _Task Tracker_ được sử dụng để theo dõi số lượng tác vụ đang được xử lý, từ đó _Job Tracker_ có thể theo dõi, gán thêm một số tác vụ khác cho nó. 

Tác vụ **Reduce** là tác vụ thực hiện việc hợp nhất, rút gọn các kết quả đầu ra của các tệp thành một kết quả đầu ra duy nhất.  Trong Hadoop, càng có nhiều bộ *Reduce* thì số lượng tệp kết quả dữ liệu đầu ra càng lớn. Trong cài đặt mặc định, mỗi cụm sẽ luôn có một _Reduce_
#### b. Các hàm trong Map Reduce
Như đã đề cập ở trên, số lượng trình ánh xạ thực thi bằng số phần đầu vào dữ liệu. Mỗi trình ánh xạ sẽ chạy trên mỗi phần đầu vào. Tuy nhiên, nếu các phần đầu vào này chứa các văn bản, các trình ánh xạ không thể đọc văn bản nên các trình ánh xạ này không chạy trực tiếp trên các phần đầu vào. Trình ánh xạ (mapper) chỉ đọc hiểu được các cặp key - value nhờ _Record Reader_. Vậy nên, ta lại có, số lượng _Record Reader_ bằng với số lượng phân tách đầu vào. 
Trong Hadoop, mỗi dòng văn bản tương đương với một bản ghi (record). _Record Reader_ sẽ chuyển đổi văn bản thành cặp key - value dựa trên định dạng của tệp. 
Các định dạng (lớp) được xác định trước trong Hadoop là:
- TextInputFormat
- KeyValueTextInputFormat
- SequenceFileInputFormat
- SequenceFileAsTextInputFormat

Theo cài đặt mặc định, một tệp tin thuộc lớp _TextInputFormat_. _Record Reader_ sẽ đọc một dòng (một bản ghi) một lần. Trong lúc đọc tệp, nó không xem xét định dạng của tệp. Tuy nhiên, _Record Reader_ chuyển đổi từng bản ghi thành cặp key - value tùy thuộc vào định dạng của tệp. Số lượng bản ghi bằng số lượng cặp key - value. Tiếp theo, Mapper sẽ chạy, thực thi lệnh trên các cặp key-value này. Từ đó, Hadoop chia nhiệm vụ lớn thành các tác vụ nhỏ hơn và thực thi chúng song song. 
#### c. Sắp xếp và trộn 
![Hình ảnh](https://techvccloud.mediacdn.vn/280518386289090560/2022/5/24/cac-ham-hay-dung-trong-mapreduce-1653380120983504915134.jpg)

Trình ánh xạ (Mapper) cung cấp kết quả đầu ra tương ứng với các cặp key - value do _Record Reader_ cung cấp. Dữ liệu trung gian (Intermediate Data) là dữ liệu trùng lặp cần được xử lý trước khi chuyển đến Reducer. 

Trước khi chuyển dữ liệu trung gian đến Reducer, dữ liệu sẽ được chuyển qua 2 giai đoạn là Trộn dữ liệu (Shuffling) và Sắp xếp dữ liệu (Sorting).
- Giai đoạn trộn dữ liệu: bao gồm việc kết hợp tất cả các giá trị được liên kết với một khóa giống hệt nhau
- Giai đoạn sắp xếp dữ liệu: sau khi dữ liệu đã được trộn, kết quả đầu ra được gửi đến tác vụ sắp xếp. Tại đây, các cặp key - value được sắp xếp tự động. Trong Hadoop, việc sắp xếp có một quy trình tự động nhờ giao diện có sẵn là **WritableComparableInterface**
- Sau khi dữ liệu đã được sắp xếp, kết quả được gửi đến _Reducer_. Nếu kết quả có n cặp key - value thì _Reducer_ sẽ thực thi n lần. Kết quả cuối cùng sẽ được lưu trữ trong tư mục chỉ định trong câu truy vấn được viết.

### 2.4. Apache Spark
Trong các công việc liên quan đến BigData, một hệ thống dữ liệu thông thường thường bao gồm hai thành phần Hadoop và Spark, dùng để lưu trữ và xử lý dữ liệu. Spark có khả năng tích hợp mạnh mã trong Hadoop Ecosystem, có thể xử lý dữ liệu dạng Batch/Neal real-time, có sẵn có API phục vụ Machine Learning/Graph Processing chạy phân tán với độ ổn định cao. Spark cung cấp các API cấp cao bằng Python, Scala, Java và R. Các tác vụ song song được viết rất dễ dàng.
Apache Spark xử lý một lượng lớn bộ dữ liệu. Tính năng quan trọng nhất của nó là tính toán cụm trong bộ nhớ, nhờ vậy tốc độ xử lý dữ liệu có thể tăng. 
#### a. Các thành phần trong Apache Spark
![Hình ảnh](https://media.geeksforgeeks.org/wp-content/uploads/20200616181455/spark2.png)

**Spark Core**: Đây là công cụ thực thi chung làm nền tảng cho Spark. Tất cả các chức năng khác được xây dựa trên nền tảng Spark Core. Nó cung cấp khả năng tính toán trong bộ nhớ, nhờ vậy tốc độ xử lý dữ liệu tăng. _Spark Core_ là nền tảng xử lý song song và phân tán của tập dữ liệu khổng lồ. Đây là thành phần cốt lõi của các tính năng thiết yếu I/O, có ý nghĩa quan trọng trong quá trình lập trình. Thành phần này chứa các thành phần liên quan đến lập lịch, phân phối, giám sát công việc trên cụm, gửi tác vụ, khôi phục lỗi.
Chức năng của _Spark Core_:
- Chứa các tác vụ cơ bản của Spark: Lập lịch tác vụ, quản lý bộ nhớ, khôi phục lỗi, tương tac với hệ thống lưu trữ
- Là trang chủ (home) của API để xác định RDD.

**Spark SQL Structured Data**: Thành phần _Spark SQL_ được xây dựng phía trên _Spark Core_, được sử dụng để cung cấp quá trình xử lý có cấu trúc trên dữ liệu. Nó cung cấp quyền truy cập tiêu chuẩn vào một loạt nguồn dữ liệu gồm HIVE, JSON, JDBC. _Spark SQL_ hỗ trợ truy vấn dữ liệu, truy cập các thông tin có cấu trúc và bán cấu trúc thông qua câu lệnh SQL hoặc HIVE. Nó cũng cung cấp ứng dụng phân tích, tương tác, mạnh mẽ trên cả dữ liệu truyền phát (streaming data) và dữ liệu lịch sử (historical data).
Spark SQL tích hợp quy trình với API lập trình sẽ trở thành một module, module này có các chức năng chính:
- Module là gói Spark làm việc với dữ liệu có cấu trúc
- Hỗ trợ nhiều nguồn dữ liệu bao gồm json, parquet...
- Cho phép lập trình viên kết hợp SQK với thao tác dữ liệu có lập trình được hỗ trợ bởi RDD

**Spark Streaming**: cho phép quá trình truyền dữ liệu tri thức trực tiếp có khả năng thông qua cao, chịu lỗi cao. Spark có thể truy cập dữ liệu từ một nguồn như một ống, cổng TCP. Nó sẽ tính toán sử dụng các thuật toán khác nhau dựa vào dữ liệu nó nhận được ở hệ thống tệp, cơ sở dữ liệu và bảng điều khiển trực tiếp (live dashboard). Spark Streaming tận dụng khả năng lập lịch memory-base của Spark Core, để thực hiện streaming analytics. Nó lấy dữa liệu theo mini-batches và thực hiện các phép biến đổi RDD trên các mini-batches dữ liệu đó. Spark sử dụng _Micro - batching_ cho truyền dữ liệu thời gian thực. _Micro - batching_ là một kĩ thuật cho phép một tác vụ hoặc một phương thức xử lý một luồng dưới dạng một chuỗi các lô (batch) thông tin nhỏ. 
> RDD (Bộ dữ liệu phan tán có khả năng phục hồi)

Chức năng chính của thành phần:
- Có thể xử lý luồng dữ liệu thực tế như tệp log tạo bởi dịch vụ web sản xuất
- API được xác định ở module này khá tương đồng với API của Spark Core RDD.

**MLlib Machine Learning**: Thư viện học máy trong Spark là một thư viện có thể mở rộng, bao gồm nhiều thuật toán học máy như phân cụm, phân loại, lọc cộng tác, hồi quy... MLLib được sử dụng cho mục đích triển khai các thuật toán học máy một cách đơn giản. Framework này tận dụng khả năng tính toán tốc độ cao nhờ distributed memory-based của kiến trúc Spark

**GraphX graph processing**: Đây là API dành cho các đồ thị và thực thi đồ thị song song, xử lý đồ thị phân tán. Nó cung cấp API để thực hiện tính toán biểu đồ có thể mô hình hóa các biểu đồ do người dùng xác định bằng cách sử dụng API đã được tối ưu sẵn. Các hoạt động như phân cụm, phân loại, duyệt, tìm kiếm, tìm đường dẫn dữ liệu có thể thực hiện trong đồ thị. Thành phần này giúp tối uuw hóa cách biểu diễn đỉnh, cạnh trong biểu đồ dù dữ liệu là kiểu dữ liệu nguyên thủy (primitive). Ngoài ra, để hỗ trợ các phép tính toán trong đồ thị, _Graph X_ còn có một số toán tử/hoạt động cơ bản như đồ thị con, nối các đỉnh, tổng hợp thông báo như một biến được tối ưu hóa của API Pregel.

#### b. So sánh Spark vs. Hadoop MapReduce
 _**Cơ chế hoạt động của Map Reduce:**_ dữ liệu đầu vào được đọc từ HDFS (thành phần phụ trách việc lưu trữ trong Hadoop) -> xử lý bằng các thao tác chỉ định -> output được ghi vào HDFS -> dữ liệu tiếp tục được đẩy lên -> thao tác tiếp theo được thực hiện -> output tiếp tục ghi vào HDFS.... Chuỗi các bước (đọc - xử lý - ghi) được lặp đi lặp lại cho đến khi công việc hoàn thành. Vì dữ liệu input được chia thành các block độc lập với nhau, các tác vụ map-reduce được thực hiện song song, nên về cơ bản, cơ chế này rất hữu ích để xử lý bộ dữ liệu lớn. Tuy nhiên, quá trình xử lý không thực sự hiệu quả trong trường hợp phải lặp lại nhiều bước, vì mỗi bước cần thiết phải ghi kết quả đầu ra vào HDFS trước khi thực hiện bước tiếp theo. Vậy nên, các vấn đề trong lưu trữ và replicate, tăng độ trễ xử lý do phần lớn thực hiện trên Disk vốn có hiệu suất không cao. 

 ![Hình ảnh các bước trong MR](https://scontent.fhan5-8.fna.fbcdn.net/v/t1.6435-9/92040663_2562655010634071_4388925959072382976_n.jpg?_nc_cat=110&ccb=1-7&_nc_sid=8ecba9&_nc_ohc=SYsKTlq5QU4AX8gaohX&_nc_ht=scontent.fhan5-8.fna&oh=00_AfCRx2CWH2tBdfqTAR6HeqWo3SyoQrwdAxTWpCKSQHki9g&oe=65069205)
 
 _**Cơ chế hoạt động của Spark**_: cơ chế này có thể khắc phục được những hạn chế tồn tại trong Hadoop MapReduce. Spark đưa ra một khái niệm mới về _RDD (Resilient Distributed Dataset)_ đóng vai trò như một cấu trúc dữ liệu cơ bản trong Spark. RDD được định nghĩa cho một tập hợp các phần tử bất biến (được lưu trên các ô nhớ read-only), được phân vùng có thể được chia sẻ, tác động song song. Qua đó, dữ liệu đầu vào chỉ cần đẩy lên (load) một lần duy nhất, các bước thực hiện biến đổi, xử lý dữ liệu đầu vào được lên kế hoạch, tối ưu và thực hiện một cách liên tục cho đến khi kết quả đầu ra được trả khi kết thúc công việc. Toàn bộ quá trình đó được diễn ra trên bộ nhớ RAM, tận dụng hiệu suất I/O cao, từ đó có thể tiết kiệm, giảm thời gian thực thi.
 ![Hình ảnh cơ chế của Spark](https://scontent.fhan5-8.fna.fbcdn.net/v/t1.6435-9/92572786_2562655277300711_8713650386226905088_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=8ecba9&_nc_ohc=Z8mokjrKZRUAX90VNCQ&_nc_ht=scontent.fhan5-8.fna&oh=00_AfBmitAwPn5nvcT9AbPxRNYI3KklA7uG7QkT4mkhz0B5jQ&oe=65068543) 
#### c. Các tính năng chính của Spark
- Hỗ trợ nhiều ngôn ngữ: cung cấp API được viết bằng Scala, Java, Python, R. Nhờ vậy, người dùng có hể viết các ứng dụng với nhiều lựa chọn ngôn ngữ.
- Tốc độ nhanh: Tốc độ xử lý của Spark là một trong những tính năng đặc biệt, nó cho phép ứng dụng chạy trên cụm Hadoop nhanh hơn tới hàng trăm lần trong bộ nhớ và hàng chục lần trên đĩa. Điều này có được là do việc giảm số lượng hoạt động đọc/ghi vào ổ đĩa
- Thực thi mọi nơi: Spark thực thi trên nhiều nền tảng mà không làm thay đổi tốc độ xử lý. Nó có thể chạy trên Hadoop, Kubernetes, Mesos, Standalone hay Cloud
- Spark không chỉ hỗ trợ "Map" và "Reduce", nó còn hỗ trợ Spark truy vấn SQL, Streaming data, ML và các thuật toán xử lý đồ thị đóng vai trò như một bộ công cụ phân tích dữ liệu cực kỳ mạnh mẽ
- Apache Spark được sử dụng để thực hiện các phân tích nâng cao

Bên cạnh các tính năng cũng như ưu điểm trên, Spark vẫn còn một số hạn chế:
- Không có hệ thống FileSystem riêng, do đó, nó phụ thuộc một số nền tảng khác như Hadoop, nền tảng dựa trên đám mây (S3, Google Cloud Storage)
- Đòi hỏi nhiều RAM để thực thi trong bộ nhớ do đó chi phí của Spark khá cao
- Spark Streaming không thực sự real-time
- Việc tối ưu hóa, tinh chỉnh để phù hợp với các bộ dữ liệu cụ thể cần có kinh nghiệm và cần thực hiện thủ công.
#### d. Spark API (action, tranformation)
Spark cung cấp API linh hoạt, tối ưu việc gửi nhận dữ liệu dữ các máy tính. Trong một chương trình Spark, RDD là đại diện cho tập dữ liệu phân tán. Một RDD bao gồm nhiều partition nhỏ, mỗi partition đại diện cho một phần dữ liệu phân tán. Một node xử lý có thể chứa nhiều hơn một RDD partition. Theo cài đặt mặc định, dữ liệu các partition sẽ lưu trên memory. Việc chia nhỏ dữ liệu thành các partition và cơ chế lazy evaluation của Spark có thể giúp người dùng xử lý một lượng dữ liệu lớn mà chỉ cần sử dụng một dung lượng vừa phải trên RAM.

Làm việc với RDD, Spark có hai loại toán tử/thao tác chính là Transformation và Action.

**Transformation**: Một transformation là một phép biến đổi từ một RDD này sang RDD khác. Một số transformation:
- `map(func)`: RDD mới được tạo thành bằng cách áp dụng func lên toàn bộ bản ghi trên RDD ban đầu
- `filter(func: Boolean)`: RDD mới được tạo thành bằng cách áp dụng func lên toàn bộ bản ghi trên RDD ban đầu, với điều kiện chỉ lấy những bản ghi mà func trả về true

**Actions**: Sau khi các phép biến đổi hoàn tất, Action là hoạt động tương tác với kết quả đầu ra. Một số action:
- `take(n)`: lấy n bản ghi từ RDD về driver
- `collect`: lấy tất cả RDD về driver
- `saveAsTextFile("path")`: ghi dữ liệu RDD ra file
- `count`: đếm số bản ghi của RDD

**Lazy evaluation**: Khi thực thi, gọi các transformation, Spark không thực thi các phép tính toán ngay lập tức mà nó sẽ lưu lại thành một lineage (một tập hợp các biến đổi từ RDD này sang RDD khác) qua mỗi transformation. Khi một action được gọi, Spark mới thực sự thực hiện các biến đổi để trả về kết quả. Nhờ vậy, chỉ cần dung lượng RAM vừa phải không quá lớn, ta vẫn có thể xử lý được lượng lớn dữ liệu. 

### 3. Tìm hiểu nâng cao

#### 3.1. HA trong hdfs (khái niệm JournalNode, zookeeper)
Tính khả dụng cao (High Availability - HA) là một tính năng bổ sung cho các phiên bản Hadoop 2.x để giải quyết vấn đề khi một điểm đơn bị lỗi trong các phiên bản cũ. 
Trong các phiên bản cũ Hadoop 1.x, vì Hadoop HDFS tuân theo kiến trúc master-slave trong đó NameNode là nút master, duy trì cây hệ thống tệp. Nó là nút duy nhất điều phối hoạt động toàn cụm, mọi yêu cầu trong cụm đều phải đi qua đây, dẫn đến một số vấn đề/hạn chế sau: 
- Nếu NameNode hay máy chú bị lỗi, mọi hoạt động trong cụm đều sẽ dừng lại, không thể thực hiện các thao tác đọc ghi dữ liệu nữa
- Nếu muốn nâng cấp hệ thống, phần cứng hoặc phần mềm trên máy chủ cài NameNode thì hệ thống cũng sẽ bị downtime

Kiến trúc NameNode High Availability ra đời, trong cụm sẽ tồn tại 2 NameNode chạy đồng thời, 1 Active & 1 Standby cho phép cụm tăng khả năng chịu lỗi
![Hình ảnh](https://scontent.fhan5-11.fna.fbcdn.net/v/t1.6435-9/92722311_2155493257929745_7552503387888025600_n.jpg?_nc_cat=111&ccb=1-7&_nc_sid=8ecba9&_nc_ohc=rFJp4_ATp3gAX-iz-wH&_nc_ht=scontent.fhan5-11.fna&oh=00_AfChVrfuQGUL3uORNRXkljSFwJf3fEH_IhkagYZZOoVWjA&oe=65065572)

Trong NameNode High Availability, tại một thời điểm chỉ có một NameNode (Active), NameNode này chịu trách nhiệm cho toàn bộ các hoạt động trong cụm, đồng thời cập nhật metadata. Standby NameNode có nhiệm vụ đồng bộ metadata với Active NameNode, đảm bảo rằng có thể thay thế vị trí của Active NameNode nếu trường hợp NameNode bị lỗi.

**b. Khái niệm Journal Node**
Để thực hiện việc đồng bộ metadata, Active NameNode và Standby NameNode sẽ giao tiếp với một cụm **Quorum Journal Node (QJM)** gồm nhiều Journal Node. Các hoạt động của Client đều được Active NameNode cập nhật và ghi lại trong editLogs ở các JournalNode. Standby NameNode sẽ đọc các thay đổi này và cập nhật metadata mới nhất. 

Số lượng Journal Node trong một cụm Quorum phải là số lẻ 3, 5 hoặc 7 vì Active NamNode cần ghi xuống các Journal Node này. Nếu có vấn đề bất thường xảy ra với dữ liệu, các Journal Node sẽ vote để tìm ra phiên bản chiếm đa số vote, tương đương dữ liệu đúng. 

Tại một thời điểm Journal Node chỉ cho phép Active NameNode được quyền ghi, còn StandBy NameNameNode chỉ được quyền đọc. Các DataNode kết nối đến cả hai NameNode và đồng thời báo cáo tình trạng cũng như thông tin block đến 2 NameNode.

Lưu ý:
- Số lượng Journal Node càng nhiều thì khả năng chịu lỗi càng cao. Tuy nhiên, điều này cũng tương đương với việc quá trình đồng bộ giữa các Journal Node chậm hơn, tốn tài nguyên hơn.
- Các DataNode kết nối đến cả hai NameNode và đồng thời báo cáo tình trạng cũng như thông tin block đến 2 NameNode: nhằm mục đích StandBy NameNOde cập nhật metadata và việc failover diễn ra nhanh chóng, các DataNode cần cấu hình trỏ đến cả 2 NameNode, làm cho thông tin block cập nhật liên tục giữa hai NameNode. 
- Nếu DataNode chỉ cập nhật thành công cho một NameNode và không thành công cho NameNode còn lại: 
	- Nếu NameNode cập nhật không thành công là Active NameNode: DataNode này được đánh dấu là dead
	- Ngược lại, không có gì xảy ra. Chỉ khi StandBy NameNode trở thành Active NameNode thì DataNode sẽ bị đánh dấu là dead.

**c. Zookeeper**
Để tự động hóa việc failover giữa các Namenode, hai tiến trình _Zookeeper Quorum và ZKFailoverController (ZKFC) được sử dụng.

![Hinh ank](https://scontent.fhan5-11.fna.fbcdn.net/v/t1.6435-9/92695412_2155495867929484_6271291433487958016_n.jpg?_nc_cat=111&ccb=1-7&_nc_sid=8ecba9&_nc_ohc=APnvgdcPfzcAX_Kkx80&_nc_ht=scontent.fhan5-11.fna&oh=00_AfAjtFLlkzUiT3xjNZ4iZLTVP4_hdAk7Ig9qZsxaOibNpw&oe=6506346A) 

Kiến trúc NameNode High Availability với Automatic Failover có các điểm chính:
- Fail detection: cả hai NameNode đều giữ một session trong Zookeeper. Nếu Active NameNode fail, session này sẽ hết hạn và failover xảy ra
- Zookeeper cung cấp cơ chế cho việc chọn Active NameNode. Nếu Active NameNode hiện tại bị lỗi, StandBy NameNode sẽ chiếm lấy một lock đặc biệt trong Zookeeper ám chỉ nó sẽ là Active NameNode.
Ngoài Zookeeper, tiến trình ZKFC thường được cài đặt cùng NameNode nhằm mục đích:
- ZKFC ping đến NameNode định kỳ để kiểm tra tình trạng của NameNode
- Khi Active NameNode không gặp lỗi, nó sẽ chiếm và khóa một znode trong Zookeeper. Khóa này sẽ tồn tại đến khi NameNode này không còn active

#### 3.2.  Khái niệm editlog, stand by namenode, fs image

NameNode lưu mọi thông tin về hệ thống tệp tin trong file _FsImage_. Tệp tin này cùng với các bản ghi về tất cả các thao tác trong hệ thống (được gọi là _EditLog_) được lưu trong hệ thống file của hệ điều hành mà NameNode được cài đặt. File FsImage và EditLog được nhân bản để đề phòng trường hợp xảy ra lỗi trên NameNode.

FsImage (lưu thông tin về hệ thống tập tin) và EditLog (lưu lại thao tác trong hệ thống) là cấu trúc dữ liệu trung tâm của toàn bộ HDFS. Nếu hai file này bị lỗi, toàn bộ hệ thống HDFS có thể không hoạt động được. Vì vậy, NameNoded được cấu hình để duy trì nhiều bản sao của FsImage và EditLog. Thông tin cập nhật vào một phiên bản sẽ đồng bộ sang tất cả phiên bản khác. 
### 8. Tài liệu tham khảo
[1] https://github.com/Jiamim/ecneics-atad/blob/master/Big%20Data%20-%20Principles%20and%20best%20practices%20of%20scalable%20realtime%20data%20systems%202015.pdf

[2] [Spark in Action](https://github.com/jgperrin/net.jgp.books.spark.ch01)

[3] [GeeksforGeeks: Atomy of File Read and Write in HDFS](https://www.geeksforgeeks.org/anatomy-of-file-read-and-write-in-hdfs/)

[4] [GeeksforGeeks: Hadoop - HDFS (Hadoop Distributed File System](https://www.geeksforgeeks.org/hadoop-hdfs-hadoop-distributed-file-system/)

[5] [GeeksforGeeks: Components of Apache Spark](https://www.geeksforgeeks.org/components-of-apache-spark/)

[6] [GeeksforGeeks: Map Reduce in Hadoop](https://www.geeksforgeeks.org/map-reduce-in-hadoop/)

[7] [GeeksforGeeks: Hadoop - Reducer in Map Reduce](https://www.geeksforgeeks.org/hadoop-reducer-in-map-reduce/)

[8] [Hadoop - Features of Hadoop which makes it popular](https://www.geeksforgeeks.org/hadoop-features-of-hadoop-which-makes-it-popular/)

[9] [tutorialspoint: Hadoop - MapReduce](https://www.tutorialspoint.com/hadoop/hadoop_mapreduce.htm)

[10] [Bizfly cloud: MapReduce là gì? Tổng quan thông tin về mô hình lập trình Map Reduce](https://bizflycloud.vn/tin-tuc/mapreduce-la-gi-20220524152927617.htm)

[11][Luồng đọc ghi file trong HDFS](https://www.facebook.com/legacy/notes/504354170443438/)

[12][NameNode High Availability with QJM](https://www.facebook.com/legacy/notes/508241020054753)



